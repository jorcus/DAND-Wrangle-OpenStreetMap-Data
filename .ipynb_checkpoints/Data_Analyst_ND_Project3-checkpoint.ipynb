{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Data Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems Encountered in the Map\n",
    "Discuss the five main problems with the data in the following order:\n",
    "\n",
    "- Over­abbreviated street names (“S Tryon St Ste 105”)\n",
    "\n",
    "- Second level “k” tags with the value \"type\"(which overwrites the element’s previously processed node[“type”]field).\n",
    "\n",
    "- Street names in second ­level “k” tags pulled from Tiger GPS data and divided into segments, in the following format:\n",
    "\n",
    "- Unstructure Unique ID (1, 42653, 2321, 5030230)\n",
    "\n",
    "\n",
    "###  Map Area - Dataset\n",
    "\n",
    "In this project, I choose San Jose which is a large city surrounded by rolling hills in Silicon Valley, a major technology hub in California's Bay Area. I want to learn more about the place to see what database querying reveals. This location is one of my dreams working area as it's all over the world-class Tech corporations around there. \n",
    "\n",
    "San Jose, United States (OSM XML: 364.6 MB)\n",
    "- https://mapzen.com/data/metro-extracts/metro/san-jose_california/ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset folder: ./san-jose_california.osm\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pprint\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import os\n",
    "\n",
    "DATASET = \"san-jose_california.osm\" # osm filename\n",
    "PATH = \"./\" # directory contain the osm file\n",
    "OSMFILE = PATH + DATASET\n",
    "print('Dataset folder:', OSMFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Parsing the OSM file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of tag:  8\n",
      "Numbers of tag elements:  4599618\n",
      "{'bounds': 1,\n",
      " 'member': 18333,\n",
      " 'nd': 1965111,\n",
      " 'node': 1679378,\n",
      " 'osm': 1,\n",
      " 'relation': 1759,\n",
      " 'tag': 705634,\n",
      " 'way': 229401}\n"
     ]
    }
   ],
   "source": [
    "# mapparser.py\n",
    "# iterative parsing\n",
    "from mapparser import count_tags, count_tags_total\n",
    "\n",
    "tags = count_tags(OSMFILE)\n",
    "print('Numbers of tag: ', len(tags))\n",
    "print('Numbers of tag elements: ', count_tags_total(tags))\n",
    "pprint.pprint(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize the tag keys.\n",
    "Categorize the tag keys in the followings:\n",
    "- \"lower\", for tags that contain only lowercase letters and are valid,\n",
    "- \"lower_colon\", for otherwise valid tags with a colon in their names,\n",
    "- \"problemchars\", for tags with problematic characters, and\n",
    "- \"other\", for other tags that do not fall into the other three categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 459030, 'lower_colon': 224633, 'other': 21969, 'problemchars': 2}\n"
     ]
    }
   ],
   "source": [
    "# tags.py\n",
    "from tags import key_type\n",
    "def process_map_tags(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "    return keys\n",
    "keys = process_map_tags(OSMFILE)\n",
    "pprint.pprint(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Unique Users\n",
    "As you can see, each of the user has their own unique ID. However, the ID is unstructured likes 1, 1005885, 1030, 100744. I structured all the unique user id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users:  1359\n",
      "User ID maximum length 7\n",
      "21694 => 0021694\n",
      "396203 => 0396203\n",
      "573196 => 0573196\n",
      "446933 => 0446933\n",
      "253748 => 0253748\n",
      "158628 => 0158628\n",
      "177477 => 0177477\n",
      "183795 => 0183795\n",
      "500006 => 0500006\n",
      "161873 => 0161873\n"
     ]
    }
   ],
   "source": [
    "# users.py\n",
    "from users import unique_user_id, max_length_user_id, structure_user_id\n",
    "\n",
    "def test():\n",
    "    users = unique_user_id(OSMFILE)\n",
    "    # structured = structure_user_id(users)\n",
    "    # pprint.pprint(structured)\n",
    "    max_length = max_length_user_id(users)\n",
    "    print('Number of users: ', len(users))\n",
    "    print('User ID maximum length', max_length)\n",
    "\n",
    "    print_limit = 10\n",
    "    for user_id in users:\n",
    "        if len(user_id) < max_length:\n",
    "            structured_id = user_id\n",
    "            while len(structured_id) < max_length:\n",
    "                structured_id = str('0' + structured_id)\n",
    "\n",
    "            if print_limit > 0:\n",
    "                print_limit -= 1\n",
    "                print(user_id, \"=>\", structured_id)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over-abbreviated Street Names\n",
    "Some basic query is over-abbreviated. I updated all the problematic address strings in the followings:\n",
    "\n",
    "- Seaboard Ave => Seaboard Avenue\n",
    "- Cherry Ave => Cherry Avenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seaboard Ave => Seaboard Avenue\n",
      "Cherry Ave => Cherry Avenue\n",
      "Greenbriar Ave => Greenbriar Avenue\n",
      "Blake Ave => Blake Avenue\n",
      "Walsh Ave => Walsh Avenue\n",
      "E Duane Ave => E Duane Avenue\n",
      "Meridian Ave => Meridian Avenue\n",
      "The Alameda Ave => The Alameda Avenue\n",
      "Hollenbeck Ave => Hollenbeck Avenue\n",
      "Foxworthy Ave => Foxworthy Avenue\n"
     ]
    }
   ],
   "source": [
    "#audit.py\n",
    "from audit import audit, update_name, street_type_re, mapping\n",
    "\n",
    "def test():\n",
    "    st_types = audit(OSMFILE)\n",
    "    # pprint.pprint(dict(st_types)) #print out dictonary of potentially incorrect street types\n",
    "    print_limit = 10\n",
    "    for st_type, ways in st_types.items(): # .iteritems() for python2\n",
    "        for name in ways:\n",
    "            if street_type_re.search(name).group() in mapping:\n",
    "                better_name = update_name(name, mapping)\n",
    "                if print_limit > 0:\n",
    "                    print_limit -= 1\n",
    "                    print (name, \"=>\", better_name)\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert data into Mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data.py\n",
    "from data import process_map\n",
    "\n",
    "data = process_map(OSMFILE, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created': {'changeset': '11686320',\n",
       "  'timestamp': '2012-05-24T03:24:59Z',\n",
       "  'uid': '14293',\n",
       "  'user': 'KindredCoda',\n",
       "  'version': '10'},\n",
       " 'id': '25457954',\n",
       " 'pos': [37.1582245, -121.6574737],\n",
       " 'type': 'node',\n",
       " 'visible': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient('localhost:27017')\n",
    "db = client.SanJose\n",
    "collection = db.SanJoseMAP\n",
    "#collection.insert(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'SanJose'), 'SanJoseMAP')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the original xml file:  348.08773612976074 MB\n",
      "Size of the processed json file:  510.8454399108887 MB\n",
      "Number of documents: 19761132\n",
      "Number of nodes: 17470242\n",
      "Number of ways: 2290674\n",
      "Number of relations: 0\n",
      "Number of unique users: 1356\n",
      "Number of pizza places: 636\n"
     ]
    }
   ],
   "source": [
    "print('Size of the original xml file: ',os.path.getsize(OSMFILE)/(1024*1024.0), 'MB')\n",
    "print('Size of the processed json file: ',os.path.getsize(os.path.join(PATH, \"san-jose_california.osm.json\"))/(1024*1024.0), 'MB')\n",
    "print('Number of documents: ' + str(collection.find().count()))\n",
    "print('Number of nodes: ' + str(collection.find({\"type\":\"node\"}).count()))\n",
    "print('Number of ways: ' + str(collection.find({\"type\":\"way\"}).count()))\n",
    "print('Number of relations: ' + str(collection.find({\"type\":\"relation\"}).count()))\n",
    "print('Number of unique users: ' + str(len(collection.distinct(\"created.user\"))))\n",
    "print('Number of pizza places: ' + str(collection.find({\"cuisine\":\"pizza\"}).count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Ideas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'nmixter', 'count': 2980568}\n",
      "{'_id': 'andygol', 'count': 2961664}\n",
      "{'_id': 'mk408', 'count': 1615791}\n",
      "{'_id': 'Bike Mapper', 'count': 969105}\n",
      "{'_id': 'samely', 'count': 813227}\n",
      "{'_id': 'RichRico', 'count': 768741}\n",
      "{'_id': 'dannykath', 'count': 752101}\n",
      "{'_id': 'MustangBuyer', 'count': 646129}\n",
      "{'_id': 'karitotp', 'count': 645535}\n",
      "{'_id': 'Minh Nguyen', 'count': 517383}\n"
     ]
    }
   ],
   "source": [
    "# Top 10 users with most contributions\n",
    "pipeline = [{\"$group\":{\"_id\": \"$created.user\", \"count\": {\"$sum\": 1}}},\n",
    "            {\"$sort\": {\"count\": -1}},\n",
    "            {\"$limit\": 10}]\n",
    "result = collection.aggregate(pipeline)\n",
    "for r in range(10):\n",
    "    print (result.next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 1, 'num_users': 1}\n"
     ]
    }
   ],
   "source": [
    "# Number of users appearing only once (having 1 post)\n",
    "pipeline = [{\"$group\":{\"_id\":\"$created.user\", \"count\":{\"$sum\":1}}},\n",
    "                      {\"$group\":{\"_id\":\"$count\", \"num_users\":{\"$sum\":1}}},\n",
    "                      {\"$sort\":{\"_id\":1}}, {\"$limit\":1}]\n",
    "\n",
    "result = collection.aggregate(pipeline)\n",
    "for r in range(1):\n",
    "    print (result.next())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "I believe it has been cleaned for the purposes of this exercise. However, some area of the San Jose data is obviously far from being complete. There's still some data haven't clean likes Inconsistent postal codes (“NC28226”, “28226­0783”, “28226”) and “Incorrect” postal codes (Charlotte area zip codes all begin with “282” however a large portion of all documented zip codes were outside this region.)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
